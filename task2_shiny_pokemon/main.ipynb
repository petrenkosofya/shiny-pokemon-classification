{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet results:\n",
    "\n",
    "Test Loss: 0.6026\n",
    "\n",
    "Test Accuracy: 0.5964\n",
    "\n",
    "## ViT results:\n",
    "\n",
    "Test Loss: 0.6563\n",
    "\n",
    "Test Accuracy: 0.6036\n",
    "\n",
    "## Swin results:\n",
    "\n",
    "Test Loss: 0.6000\n",
    "\n",
    "Test Accuracy: 0.6036"
   ],
   "metadata": {
    "id": "QizPhQy6-lcH"
   },
   "id": "QizPhQy6-lcH"
  },
  {
   "cell_type": "code",
   "source": "# Unpack the dataset\nimport zipfile\nimport os\n\nzip_path = 'shiny_dataset.zip'\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall('.')",
   "metadata": {
    "id": "rKsKbo2oN0OU"
   },
   "id": "rKsKbo2oN0OU",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fevmz977dsd",
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\n\n# Check GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fevmz977dsd",
    "outputId": "107a0236-5b58-4880-a0c6-fd39b7b24085"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bwuu569w0i",
   "source": [
    "data_dir = Path('dataset')\n",
    "train_dir = data_dir / 'train'\n",
    "val_dir = data_dir / 'val'\n",
    "test_dir = data_dir / 'test'\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Transformations for training data (with augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'Classes: {train_dataset.classes}')\n",
    "print(f'Train samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "print(f'Test samples: {len(test_dataset)}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwuu569w0i",
    "outputId": "1c2a559a-0595-4c54-f704-fd4dbe03eb07"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "l02uw78vyfr",
   "source": [
    "def frozen_parameters(model):\n",
    "    # Freeze base model weights\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def last_layer(num_features):\n",
    "    # Replace the last fully connected layer with a new one for binary classification\n",
    "    layer = nn.Sequential(\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(256, 2)\n",
    "    )\n",
    "    print(\"New classification layer:\")\n",
    "    print(layer)\n",
    "    return layer\n",
    "\n",
    "def resnet_initialization():\n",
    "    # Load pretrained ResNet152 model\n",
    "    model = models.resnet152(pretrained=True)\n",
    "    frozen_parameters(model)\n",
    "    model.fc = last_layer(model.fc.in_features)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n",
    "\n",
    "def vit_initialization():\n",
    "    # Load pretrained ViT model\n",
    "    model = models.vit_b_16(pretrained=True)\n",
    "    frozen_parameters(model)\n",
    "    model.heads.head = last_layer(model.heads.head.in_features)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.heads.head.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n",
    "\n",
    "def swin_initialization():\n",
    "    # Load pretrained Swin Transformer Base model\n",
    "    model = models.swin_b(pretrained=True)\n",
    "    frozen_parameters(model)\n",
    "    model.head = last_layer(model.head.in_features)\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.head.parameters(), lr=learning_rate)\n",
    "    return model, optimizer"
   ],
   "metadata": {
    "id": "l02uw78vyfr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "t8em8cclbi",
   "source": [
    "model, optimizer = resnet_initialization()\n",
    "#model, optimizer = vit_initialization()\n",
    "#model, optimizer = swin_initialization()\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate scheduler for improved training\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8em8cclbi",
    "outputId": "0b0e9d8c-13fa-42e2-8bab-9932dccb11cd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dzqeyghmbjm",
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Function to validate the model\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ],
   "metadata": {
    "id": "dzqeyghmbjm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "p646alope4",
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    print(f'Learning Rate: {current_lr:.6f}')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Save the best model by validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'Best model saved! Val Loss: {val_loss:.4f}')\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "print(\"Training completed!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p646alope4",
    "outputId": "ef278271-8a5e-496f-a01a-5a4083d4f6d4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "jb6yoih05l",
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss function plot\n",
    "ax1.plot(train_losses, label='Train Loss', marker='o')\n",
    "ax1.plot(val_losses, label='Validation Loss', marker='o')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_ylim(top=1)\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(train_accs, label='Train Accuracy', marker='o')\n",
    "ax2.plot(val_accs, label='Validation Accuracy', marker='o')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_ylim(bottom=0)\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "jb6yoih05l",
    "outputId": "5db2a6cb-46d3-4004-a5bb-df0d4b0bbd85"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "sxfg12fu82b",
   "source": [
    "# Load the best model for testing\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss, test_acc = validate_epoch(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxfg12fu82b",
    "outputId": "b88123f3-0ab5-431f-ad04-901cc1ea4e33"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8s506n6ht9",
   "source": [
    "def predict_with_probabilities(model, image_path, device):\n",
    "    model.eval()\n",
    "\n",
    "    # Load and preprocess image\n",
    "    image = datasets.folder.default_loader(image_path)\n",
    "    image_tensor = val_test_transforms(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)[0].cpu().numpy()\n",
    "        predicted_class = torch.argmax(output, 1).item()\n",
    "\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "    print(f\"Predicted class: {class_names[predicted_class]}\")\n",
    "    print(f\"Probabilities:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"  {class_name}: {probabilities[i]:.4f} ({probabilities[i]*100:.2f}%)\")\n",
    "\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "import random\n",
    "test_image = random.choice([f for f in test_dir.rglob('*.png')])\n",
    "print(f\"Testing on image: {test_image}\")\n",
    "predict_with_probabilities(model, test_image, device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s506n6ht9",
    "outputId": "01eb854a-7be3-4bb1-a703-cb2a1ea1412e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fhq81gv9f5",
   "source": [
    "# Visualize several predictions\n",
    "def visualize_predictions(model, dataset, device, num_images=8):\n",
    "    model.eval()\n",
    "\n",
    "    # Select random images\n",
    "    indices = random.sample(range(len(dataset)), num_images)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for idx, ax in zip(indices, axes):\n",
    "        image_path = dataset.samples[idx][0]\n",
    "        true_label = dataset.samples[idx][1]\n",
    "\n",
    "        original_image = datasets.folder.default_loader(image_path)\n",
    "        image_tensor = dataset.transform(original_image).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor)\n",
    "            probabilities = torch.softmax(output, dim=1)[0].cpu().numpy()\n",
    "            predicted_label = torch.argmax(output, 1).item()\n",
    "\n",
    "        ax.imshow(original_image)\n",
    "        ax.axis('off')\n",
    "\n",
    "        class_names = dataset.classes\n",
    "        pred_class = class_names[predicted_label]\n",
    "        true_class = class_names[true_label]\n",
    "\n",
    "        # Show probability of the second class (shiny)\n",
    "        # If >0.5 - prediction is shiny, if <0.5 - normal\n",
    "        shiny_prob = probabilities[1]\n",
    "\n",
    "        color = 'green' if predicted_label == true_label else 'red'\n",
    "        title = f'True: {true_class}\\nShiny prob: {shiny_prob:.3f}'\n",
    "        ax.set_title(title, color=color, fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions on test set\n",
    "visualize_predictions(model, test_dataset, device, num_images=8)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "fhq81gv9f5",
    "outputId": "4874a736-5463-4998-c596-b797d9d333bf"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
